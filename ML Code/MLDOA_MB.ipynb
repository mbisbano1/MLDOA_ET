{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the neccesary libraries needed\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "import numpy as np\n",
    "from numpy import insert\n",
    "import os\n",
    "import time\n",
    "\n",
    "# keras tuner for hyperparameter tuning\n",
    "import keras_tuner as kt\n",
    "\n",
    "# tensorflow Libraries\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import sparse_categorical_crossentropy\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the CSV Training and Testing Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the csv's (IMPORTANT: You need at least 16 Gb of RAM to proceed)\n",
    "\n",
    "# Original Dataset (002)\n",
    "#train = pd.read_csv('D:\\\\OneDrive\\\\OneDrive - University of Massachusetts Dartmouth\\\\ECE457_Senior_Design_ECE5\\\\CSV_Files\\\\PortTraining_1404_002_FINAL_startingAt24.csv')\n",
    "#test = pd.read_csv('D:\\\\OneDrive\\\\OneDrive - University of Massachusetts Dartmouth\\\\ECE457_Senior_Design_ECE5\\\\CSV_Files\\\\StbdTesting_1404_002_FINAL.csv')\n",
    "\n",
    "# Deeper More Variate Dataset (038)\n",
    "#train38 = pd.read_csv('D:\\\\OneDrive\\\\OneDrive - University of Massachusetts Dartmouth\\\\ECE457_Senior_Design_ECE5\\\\CSV_Files\\\\0001_1404.038_port.csv')\n",
    "#test38 = pd.read_csv('D:\\\\OneDrive\\\\OneDrive - University of Massachusetts Dartmouth\\\\ECE457_Senior_Design_ECE5\\\\CSV_Files\\\\0001_1404.038_stbd.csv')\n",
    "\n",
    "\n",
    "# Joint Noise Reduction Datasets\n",
    "train = pd.read_csv('D:\\\\OneDrive\\\\OneDrive - University of Massachusetts Dartmouth\\\\ECE457_Senior_Design_ECE5\\\\CSV_Files\\\\0001_1404.038_port_FinalCleaned_RollReady.csv')\n",
    "#train2 = pd.read_csv('D:\\\\OneDrive\\\\OneDrive - University of Massachusetts Dartmouth\\\\ECE457_Senior_Design_ECE5\\\\CSV_Files\\\\0001_1404.002_port_FinalCleaned_RollReady.csv')\n",
    "test = pd.read_csv('D:\\\\OneDrive\\\\OneDrive - University of Massachusetts Dartmouth\\\\ECE457_Senior_Design_ECE5\\\\CSV_Files\\\\0001_1404.038_stbd_FinalCleaned_RollReady.csv')\n",
    "#test2 = pd.read_csv('D:\\\\OneDrive\\\\OneDrive - University of Massachusetts Dartmouth\\\\ECE457_Senior_Design_ECE5\\\\CSV_Files\\\\0001_1404.002_stbd_FinalCleaned_RollReady.csv')\n",
    "\n",
    "# 0005_1217 Dataset:\n",
    "#train = pd.read_csv('D:\\\\OneDrive\\\\OneDrive - University of Massachusetts Dartmouth\\\\ECE457_Senior_Design_ECE5\\\\CSV_Files\\\\CSVs_0005_1217\\\\0005_1217_port_FinalCleaned_RollReady.csv')\n",
    "#test = pd.read_csv('D:\\\\OneDrive\\\\OneDrive - University of Massachusetts Dartmouth\\\\ECE457_Senior_Design_ECE5\\\\CSV_Files\\\\CSVs_0005_1217\\\\0005_1217_stbd_FinalCleaned_RollReady.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PingNum</th>\n",
       "      <th>SampleNum</th>\n",
       "      <th>PortStbd</th>\n",
       "      <th>SampleTimeDelay</th>\n",
       "      <th>I1</th>\n",
       "      <th>Q1</th>\n",
       "      <th>I2</th>\n",
       "      <th>Q2</th>\n",
       "      <th>I3</th>\n",
       "      <th>Q3</th>\n",
       "      <th>...</th>\n",
       "      <th>I10</th>\n",
       "      <th>Q10</th>\n",
       "      <th>Roll</th>\n",
       "      <th>C</th>\n",
       "      <th>DOA</th>\n",
       "      <th>TWTT</th>\n",
       "      <th>Amplitude</th>\n",
       "      <th>AngleUncertainty</th>\n",
       "      <th>SampleRate</th>\n",
       "      <th>Range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1719881</th>\n",
       "      <td>85276</td>\n",
       "      <td>2723</td>\n",
       "      <td>0</td>\n",
       "      <td>0.041807</td>\n",
       "      <td>46.3750</td>\n",
       "      <td>-1.8125</td>\n",
       "      <td>-20.7500</td>\n",
       "      <td>40.9375</td>\n",
       "      <td>-14.0625</td>\n",
       "      <td>-60.1250</td>\n",
       "      <td>...</td>\n",
       "      <td>-46.3125</td>\n",
       "      <td>31.3125</td>\n",
       "      <td>-0.401001</td>\n",
       "      <td>1531.56</td>\n",
       "      <td>-2.514000</td>\n",
       "      <td>0.041812</td>\n",
       "      <td>116</td>\n",
       "      <td>10</td>\n",
       "      <td>65108.40625</td>\n",
       "      <td>32.018644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1719882</th>\n",
       "      <td>85276</td>\n",
       "      <td>2725</td>\n",
       "      <td>0</td>\n",
       "      <td>0.041838</td>\n",
       "      <td>-67.7500</td>\n",
       "      <td>-28.3750</td>\n",
       "      <td>88.5000</td>\n",
       "      <td>-44.3750</td>\n",
       "      <td>-49.3750</td>\n",
       "      <td>109.3750</td>\n",
       "      <td>...</td>\n",
       "      <td>136.2500</td>\n",
       "      <td>67.4375</td>\n",
       "      <td>-0.401001</td>\n",
       "      <td>1531.56</td>\n",
       "      <td>-0.702000</td>\n",
       "      <td>0.041844</td>\n",
       "      <td>131</td>\n",
       "      <td>7</td>\n",
       "      <td>65108.40625</td>\n",
       "      <td>32.043343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1719883</th>\n",
       "      <td>85276</td>\n",
       "      <td>2727</td>\n",
       "      <td>0</td>\n",
       "      <td>0.041869</td>\n",
       "      <td>384.1875</td>\n",
       "      <td>-136.0000</td>\n",
       "      <td>-200.8125</td>\n",
       "      <td>548.1875</td>\n",
       "      <td>-190.3125</td>\n",
       "      <td>-639.3750</td>\n",
       "      <td>...</td>\n",
       "      <td>-601.3750</td>\n",
       "      <td>645.3750</td>\n",
       "      <td>-0.401001</td>\n",
       "      <td>1531.56</td>\n",
       "      <td>1.110000</td>\n",
       "      <td>0.041876</td>\n",
       "      <td>148</td>\n",
       "      <td>6</td>\n",
       "      <td>65108.40625</td>\n",
       "      <td>32.068043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1719884</th>\n",
       "      <td>85276</td>\n",
       "      <td>2729</td>\n",
       "      <td>0</td>\n",
       "      <td>0.041899</td>\n",
       "      <td>131.4375</td>\n",
       "      <td>-61.5625</td>\n",
       "      <td>-87.2500</td>\n",
       "      <td>240.0625</td>\n",
       "      <td>-47.3125</td>\n",
       "      <td>-256.5000</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.4375</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>-0.401001</td>\n",
       "      <td>1531.56</td>\n",
       "      <td>2.292000</td>\n",
       "      <td>0.041902</td>\n",
       "      <td>161</td>\n",
       "      <td>7</td>\n",
       "      <td>65108.40625</td>\n",
       "      <td>32.088037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1719885</th>\n",
       "      <td>85276</td>\n",
       "      <td>2730</td>\n",
       "      <td>0</td>\n",
       "      <td>0.041915</td>\n",
       "      <td>-3.5625</td>\n",
       "      <td>185.7500</td>\n",
       "      <td>-178.2500</td>\n",
       "      <td>-151.9375</td>\n",
       "      <td>266.8750</td>\n",
       "      <td>28.3125</td>\n",
       "      <td>...</td>\n",
       "      <td>-25.4375</td>\n",
       "      <td>-377.6250</td>\n",
       "      <td>-0.401001</td>\n",
       "      <td>1531.56</td>\n",
       "      <td>2.568000</td>\n",
       "      <td>0.041919</td>\n",
       "      <td>158</td>\n",
       "      <td>10</td>\n",
       "      <td>65108.40625</td>\n",
       "      <td>32.100975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14213958</th>\n",
       "      <td>88251</td>\n",
       "      <td>6499</td>\n",
       "      <td>0</td>\n",
       "      <td>0.099803</td>\n",
       "      <td>-5.7500</td>\n",
       "      <td>11.8750</td>\n",
       "      <td>10.2500</td>\n",
       "      <td>16.7500</td>\n",
       "      <td>7.6250</td>\n",
       "      <td>-10.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>-26.1250</td>\n",
       "      <td>-5.6250</td>\n",
       "      <td>-1.395264</td>\n",
       "      <td>1531.17</td>\n",
       "      <td>80.454001</td>\n",
       "      <td>0.099801</td>\n",
       "      <td>150</td>\n",
       "      <td>10</td>\n",
       "      <td>65108.40625</td>\n",
       "      <td>76.406335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14213959</th>\n",
       "      <td>88251</td>\n",
       "      <td>6500</td>\n",
       "      <td>0</td>\n",
       "      <td>0.099818</td>\n",
       "      <td>-23.2500</td>\n",
       "      <td>-16.2500</td>\n",
       "      <td>-20.0000</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>-10.0000</td>\n",
       "      <td>15.3750</td>\n",
       "      <td>...</td>\n",
       "      <td>4.5000</td>\n",
       "      <td>-8.6250</td>\n",
       "      <td>-1.395264</td>\n",
       "      <td>1531.17</td>\n",
       "      <td>80.478001</td>\n",
       "      <td>0.099817</td>\n",
       "      <td>149</td>\n",
       "      <td>17</td>\n",
       "      <td>65108.40625</td>\n",
       "      <td>76.418094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14213960</th>\n",
       "      <td>88251</td>\n",
       "      <td>6501</td>\n",
       "      <td>0</td>\n",
       "      <td>0.099833</td>\n",
       "      <td>-24.8750</td>\n",
       "      <td>-31.7500</td>\n",
       "      <td>-41.8750</td>\n",
       "      <td>-1.2500</td>\n",
       "      <td>-21.1250</td>\n",
       "      <td>39.1250</td>\n",
       "      <td>...</td>\n",
       "      <td>35.3750</td>\n",
       "      <td>-11.1250</td>\n",
       "      <td>-1.395264</td>\n",
       "      <td>1531.17</td>\n",
       "      <td>80.478001</td>\n",
       "      <td>0.099832</td>\n",
       "      <td>148</td>\n",
       "      <td>17</td>\n",
       "      <td>65108.40625</td>\n",
       "      <td>76.429853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14213961</th>\n",
       "      <td>88251</td>\n",
       "      <td>6502</td>\n",
       "      <td>0</td>\n",
       "      <td>0.099849</td>\n",
       "      <td>-6.7500</td>\n",
       "      <td>-18.1250</td>\n",
       "      <td>-22.5000</td>\n",
       "      <td>-3.7500</td>\n",
       "      <td>-8.3750</td>\n",
       "      <td>32.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>29.5000</td>\n",
       "      <td>-7.3750</td>\n",
       "      <td>-1.395264</td>\n",
       "      <td>1531.17</td>\n",
       "      <td>80.442001</td>\n",
       "      <td>0.099847</td>\n",
       "      <td>149</td>\n",
       "      <td>16</td>\n",
       "      <td>65108.40625</td>\n",
       "      <td>76.441611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14213962</th>\n",
       "      <td>88251</td>\n",
       "      <td>6503</td>\n",
       "      <td>0</td>\n",
       "      <td>0.099864</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.5000</td>\n",
       "      <td>7.3750</td>\n",
       "      <td>10.8750</td>\n",
       "      <td>16.3750</td>\n",
       "      <td>10.1250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>-13.2500</td>\n",
       "      <td>-1.395264</td>\n",
       "      <td>1531.17</td>\n",
       "      <td>80.484001</td>\n",
       "      <td>0.099863</td>\n",
       "      <td>150</td>\n",
       "      <td>16</td>\n",
       "      <td>65108.40625</td>\n",
       "      <td>76.453370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12494082 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          PingNum  SampleNum  PortStbd  SampleTimeDelay        I1        Q1  \\\n",
       "1719881     85276       2723         0         0.041807   46.3750   -1.8125   \n",
       "1719882     85276       2725         0         0.041838  -67.7500  -28.3750   \n",
       "1719883     85276       2727         0         0.041869  384.1875 -136.0000   \n",
       "1719884     85276       2729         0         0.041899  131.4375  -61.5625   \n",
       "1719885     85276       2730         0         0.041915   -3.5625  185.7500   \n",
       "...           ...        ...       ...              ...       ...       ...   \n",
       "14213958    88251       6499         0         0.099803   -5.7500   11.8750   \n",
       "14213959    88251       6500         0         0.099818  -23.2500  -16.2500   \n",
       "14213960    88251       6501         0         0.099833  -24.8750  -31.7500   \n",
       "14213961    88251       6502         0         0.099849   -6.7500  -18.1250   \n",
       "14213962    88251       6503         0         0.099864    0.0000    2.5000   \n",
       "\n",
       "                I2        Q2        I3        Q3  ...       I10       Q10  \\\n",
       "1719881   -20.7500   40.9375  -14.0625  -60.1250  ...  -46.3125   31.3125   \n",
       "1719882    88.5000  -44.3750  -49.3750  109.3750  ...  136.2500   67.4375   \n",
       "1719883  -200.8125  548.1875 -190.3125 -639.3750  ... -601.3750  645.3750   \n",
       "1719884   -87.2500  240.0625  -47.3125 -256.5000  ...   -9.4375    0.7500   \n",
       "1719885  -178.2500 -151.9375  266.8750   28.3125  ...  -25.4375 -377.6250   \n",
       "...            ...       ...       ...       ...  ...       ...       ...   \n",
       "14213958   10.2500   16.7500    7.6250  -10.0000  ...  -26.1250   -5.6250   \n",
       "14213959  -20.0000   11.5000  -10.0000   15.3750  ...    4.5000   -8.6250   \n",
       "14213960  -41.8750   -1.2500  -21.1250   39.1250  ...   35.3750  -11.1250   \n",
       "14213961  -22.5000   -3.7500   -8.3750   32.0000  ...   29.5000   -7.3750   \n",
       "14213962    7.3750   10.8750   16.3750   10.1250  ...    0.3750  -13.2500   \n",
       "\n",
       "              Roll        C        DOA      TWTT  Amplitude  AngleUncertainty  \\\n",
       "1719881  -0.401001  1531.56  -2.514000  0.041812        116                10   \n",
       "1719882  -0.401001  1531.56  -0.702000  0.041844        131                 7   \n",
       "1719883  -0.401001  1531.56   1.110000  0.041876        148                 6   \n",
       "1719884  -0.401001  1531.56   2.292000  0.041902        161                 7   \n",
       "1719885  -0.401001  1531.56   2.568000  0.041919        158                10   \n",
       "...            ...      ...        ...       ...        ...               ...   \n",
       "14213958 -1.395264  1531.17  80.454001  0.099801        150                10   \n",
       "14213959 -1.395264  1531.17  80.478001  0.099817        149                17   \n",
       "14213960 -1.395264  1531.17  80.478001  0.099832        148                17   \n",
       "14213961 -1.395264  1531.17  80.442001  0.099847        149                16   \n",
       "14213962 -1.395264  1531.17  80.484001  0.099863        150                16   \n",
       "\n",
       "           SampleRate      Range  \n",
       "1719881   65108.40625  32.018644  \n",
       "1719882   65108.40625  32.043343  \n",
       "1719883   65108.40625  32.068043  \n",
       "1719884   65108.40625  32.088037  \n",
       "1719885   65108.40625  32.100975  \n",
       "...               ...        ...  \n",
       "14213958  65108.40625  76.406335  \n",
       "14213959  65108.40625  76.418094  \n",
       "14213960  65108.40625  76.429853  \n",
       "14213961  65108.40625  76.441611  \n",
       "14213962  65108.40625  76.453370  \n",
       "\n",
       "[12494082 rows x 32 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PingNum</th>\n",
       "      <th>SampleNum</th>\n",
       "      <th>PortStbd</th>\n",
       "      <th>SampleTimeDelay</th>\n",
       "      <th>I1</th>\n",
       "      <th>Q1</th>\n",
       "      <th>I2</th>\n",
       "      <th>Q2</th>\n",
       "      <th>I3</th>\n",
       "      <th>Q3</th>\n",
       "      <th>...</th>\n",
       "      <th>I10</th>\n",
       "      <th>Q10</th>\n",
       "      <th>Roll</th>\n",
       "      <th>C</th>\n",
       "      <th>DOA</th>\n",
       "      <th>TWTT</th>\n",
       "      <th>Amplitude</th>\n",
       "      <th>AngleUncertainty</th>\n",
       "      <th>SampleRate</th>\n",
       "      <th>Range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1716044</th>\n",
       "      <td>85276</td>\n",
       "      <td>2724</td>\n",
       "      <td>1</td>\n",
       "      <td>0.041823</td>\n",
       "      <td>-5.0000</td>\n",
       "      <td>-24.7500</td>\n",
       "      <td>33.5000</td>\n",
       "      <td>10.5625</td>\n",
       "      <td>-26.5000</td>\n",
       "      <td>3.5625</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.9375</td>\n",
       "      <td>45.3750</td>\n",
       "      <td>-0.401001</td>\n",
       "      <td>1531.56</td>\n",
       "      <td>-3.342000</td>\n",
       "      <td>0.041819</td>\n",
       "      <td>127</td>\n",
       "      <td>13</td>\n",
       "      <td>65108.40625</td>\n",
       "      <td>32.024525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1716045</th>\n",
       "      <td>85276</td>\n",
       "      <td>2725</td>\n",
       "      <td>1</td>\n",
       "      <td>0.041838</td>\n",
       "      <td>44.0000</td>\n",
       "      <td>25.1875</td>\n",
       "      <td>-48.2500</td>\n",
       "      <td>17.5625</td>\n",
       "      <td>49.4375</td>\n",
       "      <td>-64.1875</td>\n",
       "      <td>...</td>\n",
       "      <td>-80.2500</td>\n",
       "      <td>-121.5000</td>\n",
       "      <td>-0.401001</td>\n",
       "      <td>1531.56</td>\n",
       "      <td>-2.328000</td>\n",
       "      <td>0.041844</td>\n",
       "      <td>142</td>\n",
       "      <td>9</td>\n",
       "      <td>65108.40625</td>\n",
       "      <td>32.043343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1716046</th>\n",
       "      <td>85276</td>\n",
       "      <td>2726</td>\n",
       "      <td>1</td>\n",
       "      <td>0.041853</td>\n",
       "      <td>-52.6875</td>\n",
       "      <td>164.6250</td>\n",
       "      <td>-120.6875</td>\n",
       "      <td>-165.5000</td>\n",
       "      <td>235.6875</td>\n",
       "      <td>68.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>148.1250</td>\n",
       "      <td>-235.4375</td>\n",
       "      <td>-0.401001</td>\n",
       "      <td>1531.56</td>\n",
       "      <td>-2.118000</td>\n",
       "      <td>0.041861</td>\n",
       "      <td>153</td>\n",
       "      <td>10</td>\n",
       "      <td>65108.40625</td>\n",
       "      <td>32.056281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1716047</th>\n",
       "      <td>85276</td>\n",
       "      <td>2729</td>\n",
       "      <td>1</td>\n",
       "      <td>0.041899</td>\n",
       "      <td>-325.5000</td>\n",
       "      <td>-46.6250</td>\n",
       "      <td>359.9375</td>\n",
       "      <td>-302.0625</td>\n",
       "      <td>-134.7500</td>\n",
       "      <td>509.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>462.1250</td>\n",
       "      <td>-26.0000</td>\n",
       "      <td>-0.401001</td>\n",
       "      <td>1531.56</td>\n",
       "      <td>-0.162000</td>\n",
       "      <td>0.041895</td>\n",
       "      <td>157</td>\n",
       "      <td>11</td>\n",
       "      <td>65108.40625</td>\n",
       "      <td>32.082157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1716048</th>\n",
       "      <td>85276</td>\n",
       "      <td>2730</td>\n",
       "      <td>1</td>\n",
       "      <td>0.041915</td>\n",
       "      <td>-271.0625</td>\n",
       "      <td>156.5000</td>\n",
       "      <td>104.9375</td>\n",
       "      <td>-396.8750</td>\n",
       "      <td>150.4375</td>\n",
       "      <td>404.9375</td>\n",
       "      <td>...</td>\n",
       "      <td>282.5625</td>\n",
       "      <td>-167.8125</td>\n",
       "      <td>-0.401001</td>\n",
       "      <td>1531.56</td>\n",
       "      <td>0.864000</td>\n",
       "      <td>0.041919</td>\n",
       "      <td>154</td>\n",
       "      <td>11</td>\n",
       "      <td>65108.40625</td>\n",
       "      <td>32.100975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14340274</th>\n",
       "      <td>88251</td>\n",
       "      <td>6499</td>\n",
       "      <td>1</td>\n",
       "      <td>0.099803</td>\n",
       "      <td>11.6250</td>\n",
       "      <td>-9.7500</td>\n",
       "      <td>-4.2500</td>\n",
       "      <td>-19.7500</td>\n",
       "      <td>-28.8750</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.8750</td>\n",
       "      <td>34.5000</td>\n",
       "      <td>-1.395264</td>\n",
       "      <td>1531.17</td>\n",
       "      <td>78.336001</td>\n",
       "      <td>0.099801</td>\n",
       "      <td>146</td>\n",
       "      <td>28</td>\n",
       "      <td>65108.40625</td>\n",
       "      <td>76.406335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14340275</th>\n",
       "      <td>88251</td>\n",
       "      <td>6500</td>\n",
       "      <td>1</td>\n",
       "      <td>0.099818</td>\n",
       "      <td>-7.6250</td>\n",
       "      <td>-11.3750</td>\n",
       "      <td>-11.8750</td>\n",
       "      <td>5.3750</td>\n",
       "      <td>-1.3750</td>\n",
       "      <td>22.3750</td>\n",
       "      <td>...</td>\n",
       "      <td>10.8750</td>\n",
       "      <td>19.2500</td>\n",
       "      <td>-1.395264</td>\n",
       "      <td>1531.17</td>\n",
       "      <td>77.862001</td>\n",
       "      <td>0.099817</td>\n",
       "      <td>148</td>\n",
       "      <td>27</td>\n",
       "      <td>65108.40625</td>\n",
       "      <td>76.418094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14340276</th>\n",
       "      <td>88251</td>\n",
       "      <td>6501</td>\n",
       "      <td>1</td>\n",
       "      <td>0.099833</td>\n",
       "      <td>-8.0000</td>\n",
       "      <td>-11.5000</td>\n",
       "      <td>-10.8750</td>\n",
       "      <td>8.0000</td>\n",
       "      <td>3.1250</td>\n",
       "      <td>15.2500</td>\n",
       "      <td>...</td>\n",
       "      <td>19.2500</td>\n",
       "      <td>7.1250</td>\n",
       "      <td>-1.395264</td>\n",
       "      <td>1531.17</td>\n",
       "      <td>77.952001</td>\n",
       "      <td>0.099832</td>\n",
       "      <td>150</td>\n",
       "      <td>16</td>\n",
       "      <td>65108.40625</td>\n",
       "      <td>76.429853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14340277</th>\n",
       "      <td>88251</td>\n",
       "      <td>6502</td>\n",
       "      <td>1</td>\n",
       "      <td>0.099849</td>\n",
       "      <td>14.0000</td>\n",
       "      <td>-23.7500</td>\n",
       "      <td>-5.2500</td>\n",
       "      <td>-22.0000</td>\n",
       "      <td>-18.7500</td>\n",
       "      <td>-13.6250</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.3750</td>\n",
       "      <td>30.6250</td>\n",
       "      <td>-1.395264</td>\n",
       "      <td>1531.17</td>\n",
       "      <td>78.084001</td>\n",
       "      <td>0.099847</td>\n",
       "      <td>151</td>\n",
       "      <td>11</td>\n",
       "      <td>65108.40625</td>\n",
       "      <td>76.441611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14340278</th>\n",
       "      <td>88251</td>\n",
       "      <td>6503</td>\n",
       "      <td>1</td>\n",
       "      <td>0.099864</td>\n",
       "      <td>20.8750</td>\n",
       "      <td>-39.0000</td>\n",
       "      <td>-14.1250</td>\n",
       "      <td>-31.2500</td>\n",
       "      <td>-24.3750</td>\n",
       "      <td>-8.1250</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.7500</td>\n",
       "      <td>50.6250</td>\n",
       "      <td>-1.395264</td>\n",
       "      <td>1531.17</td>\n",
       "      <td>78.156001</td>\n",
       "      <td>0.099863</td>\n",
       "      <td>151</td>\n",
       "      <td>10</td>\n",
       "      <td>65108.40625</td>\n",
       "      <td>76.453370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12624235 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          PingNum  SampleNum  PortStbd  SampleTimeDelay        I1        Q1  \\\n",
       "1716044     85276       2724         1         0.041823   -5.0000  -24.7500   \n",
       "1716045     85276       2725         1         0.041838   44.0000   25.1875   \n",
       "1716046     85276       2726         1         0.041853  -52.6875  164.6250   \n",
       "1716047     85276       2729         1         0.041899 -325.5000  -46.6250   \n",
       "1716048     85276       2730         1         0.041915 -271.0625  156.5000   \n",
       "...           ...        ...       ...              ...       ...       ...   \n",
       "14340274    88251       6499         1         0.099803   11.6250   -9.7500   \n",
       "14340275    88251       6500         1         0.099818   -7.6250  -11.3750   \n",
       "14340276    88251       6501         1         0.099833   -8.0000  -11.5000   \n",
       "14340277    88251       6502         1         0.099849   14.0000  -23.7500   \n",
       "14340278    88251       6503         1         0.099864   20.8750  -39.0000   \n",
       "\n",
       "                I2        Q2        I3        Q3  ...       I10       Q10  \\\n",
       "1716044    33.5000   10.5625  -26.5000    3.5625  ...  -19.9375   45.3750   \n",
       "1716045   -48.2500   17.5625   49.4375  -64.1875  ...  -80.2500 -121.5000   \n",
       "1716046  -120.6875 -165.5000  235.6875   68.0000  ...  148.1250 -235.4375   \n",
       "1716047   359.9375 -302.0625 -134.7500  509.0000  ...  462.1250  -26.0000   \n",
       "1716048   104.9375 -396.8750  150.4375  404.9375  ...  282.5625 -167.8125   \n",
       "...            ...       ...       ...       ...  ...       ...       ...   \n",
       "14340274   -4.2500  -19.7500  -28.8750   -1.0000  ...  -15.8750   34.5000   \n",
       "14340275  -11.8750    5.3750   -1.3750   22.3750  ...   10.8750   19.2500   \n",
       "14340276  -10.8750    8.0000    3.1250   15.2500  ...   19.2500    7.1250   \n",
       "14340277   -5.2500  -22.0000  -18.7500  -13.6250  ...   -5.3750   30.6250   \n",
       "14340278  -14.1250  -31.2500  -24.3750   -8.1250  ...  -10.7500   50.6250   \n",
       "\n",
       "              Roll        C        DOA      TWTT  Amplitude  AngleUncertainty  \\\n",
       "1716044  -0.401001  1531.56  -3.342000  0.041819        127                13   \n",
       "1716045  -0.401001  1531.56  -2.328000  0.041844        142                 9   \n",
       "1716046  -0.401001  1531.56  -2.118000  0.041861        153                10   \n",
       "1716047  -0.401001  1531.56  -0.162000  0.041895        157                11   \n",
       "1716048  -0.401001  1531.56   0.864000  0.041919        154                11   \n",
       "...            ...      ...        ...       ...        ...               ...   \n",
       "14340274 -1.395264  1531.17  78.336001  0.099801        146                28   \n",
       "14340275 -1.395264  1531.17  77.862001  0.099817        148                27   \n",
       "14340276 -1.395264  1531.17  77.952001  0.099832        150                16   \n",
       "14340277 -1.395264  1531.17  78.084001  0.099847        151                11   \n",
       "14340278 -1.395264  1531.17  78.156001  0.099863        151                10   \n",
       "\n",
       "           SampleRate      Range  \n",
       "1716044   65108.40625  32.024525  \n",
       "1716045   65108.40625  32.043343  \n",
       "1716046   65108.40625  32.056281  \n",
       "1716047   65108.40625  32.082157  \n",
       "1716048   65108.40625  32.100975  \n",
       "...               ...        ...  \n",
       "14340274  65108.40625  76.406335  \n",
       "14340275  65108.40625  76.418094  \n",
       "14340276  65108.40625  76.429853  \n",
       "14340277  65108.40625  76.441611  \n",
       "14340278  65108.40625  76.453370  \n",
       "\n",
       "[12624235 rows x 32 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove first X pings from train & test\n",
    "X_to_remove = 500\n",
    "startPingNumTrain = train['PingNum'].min()\n",
    "startPingNumTest = test['PingNum'].min()\n",
    "train = train[train.PingNum >= startPingNumTrain + X_to_remove ]\n",
    "test = test[test.PingNum >= startPingNumTest + X_to_remove ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split up the Features and Labels from both the Training and Testing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split up the features and labels from both the training and testing datasets\n",
    "#x_train=train.iloc[:,4:24]\n",
    "\n",
    "#x_train=train.iloc[:,3:24] # sample time delay through Q10\n",
    "\n",
    "x_train1=train.iloc[:,3:25] # sample time delay through roll\n",
    "#x_train2 = train2.iloc[:, 3:25]\n",
    "#x_train=train38.iloc[:,3:24]\n",
    "\n",
    "x_train1['Amplitude']=train.iloc[:,29]\n",
    "#x_train2['Amplitude']=train2.iloc[:,29]\n",
    "#x_train['Amplitude']=train38.iloc[:,29]\n",
    "\n",
    "\n",
    "#x_test=test.iloc[:,4:24]\n",
    "#x_test=test.iloc[:,3:24]    # sample time delay through Q10\n",
    "\n",
    "x_test=test.iloc[:,3:25]    # sample time delay through roll\n",
    "#x_test2=test2.iloc[:,3:25]    # sample time delay through roll\n",
    "#x_test['Roll'] = x_test['Roll']\n",
    "\n",
    "\n",
    "x_test['Amplitude']=test.iloc[:,29]\n",
    "#x_test2['Amplitude']=test2.iloc[:,29]\n",
    "#x_test['Amplitude']=test38.iloc[:,29]\n",
    "\n",
    "y_train1Seq=train.iloc[:,26]\n",
    "#y_train2Seq=train2.iloc[:,26]\n",
    "y_train1 = pd.DataFrame(y_train1Seq)\n",
    "#y_train2 = pd.DataFrame(y_train2Seq)\n",
    "#y_train=train38.iloc[:,26]\n",
    "\n",
    "y_testSeq=test.iloc[:,26]\n",
    "y_test = pd.DataFrame(y_testSeq)\n",
    "#y_test2Seq=test2.iloc[:,26]\n",
    "#y_test2 = pd.DataFrame(y_test2Seq)\n",
    "#y_test=test38.iloc[:,26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xframes = [x_train1, x_train2]\n",
    "xframes = [x_train1]\n",
    "x_train = pd.concat(xframes, sort=False)\n",
    "#yframes = [y_train1Seq, y_train2Seq]\n",
    "yframes = [y_train1Seq]\n",
    "y_trainSeq = pd.concat(yframes, sort=False)\n",
    "#y_train.columns=['DOA']\n",
    "y_train = pd.DataFrame(y_trainSeq)\n",
    "\n",
    "#val_xframes = [x_test, x_test2]\n",
    "val_xframes = [x_test]\n",
    "val_xtest = pd.concat(val_xframes, sort=False)\n",
    "#val_yframes = [y_test, y_test2]\n",
    "val_yframes = [y_test]\n",
    "val_ytestSeq = pd.concat(val_yframes, sort=False)\n",
    "val_ytest = pd.DataFrame(val_ytestSeq)\n",
    "#val_ytest.columns=['DOA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train\n",
    "print(y_train.shape)\n",
    "\n",
    "#y_traindf = y_train['DOA']\n",
    "#print(y_traindf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the Features from -1 to 1 so that Training is Easier for the Model ( Joint Train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3635099\n",
      "3635099\n"
     ]
    }
   ],
   "source": [
    "# Scale the Features and Labels from [-1,1]\n",
    "\n",
    "s1=MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "#s1=MinMaxScaler(feature_range=(0,1))\n",
    "x_train_scale=s1.fit_transform(x_train)     # fit transformation bounds on train data, scale train X to fit bounds...\n",
    "\n",
    "#s2=MinMaxScaler(feature_range=(0,1))\n",
    "#s2=MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "\n",
    "x_val_scale=s1.transform(val_xtest) #scale validation X to bounds...\n",
    "x_val_scale=x_val_scale\n",
    "x_val_scale[:, 21] = -x_val_scale[:, 21] # invert roll direction since this is both stbd datasets\n",
    "#y_val_scale = val_ytest.to_numpy()          # validation Y to numpy...\n",
    "\n",
    "\n",
    "x_test_scale=s1.transform(x_test)   #scale test X to bounds...\n",
    "x_test_scale=x_test_scale\n",
    "# \n",
    "x_test_scale[:, 21] = -x_test_scale[:, 21]\n",
    "\n",
    "#x_test2_scale=s1.transform(x_test2)\n",
    "#x_test2_scale[:, 21] = -x_test2_scale[:, 21]\n",
    "\n",
    "# Scale DOA's from (0 to 1)\n",
    "s2=MinMaxScaler(feature_range=(0,1))\n",
    "#y_train_scale=s2.fit_transform(y_train)\n",
    "y_train_scale= y_train.to_numpy()\n",
    "#y_val_scale = s2.transform(val_ytest)\n",
    "y_val_scale = val_ytest.to_numpy()\n",
    "#y_test_scale =s2.transform(y_test)\n",
    "y_test_scale = y_test.to_numpy()\n",
    "#y_test2_scale=s2.transform(y_test2)\n",
    "\n",
    "\n",
    "\n",
    "# separate training sets for additional/suplemental training...\n",
    "#x_train002_scale=s1.transform(x_train2)\n",
    "#x_train038_scale=s1.transform(x_train1)\n",
    "#y_train002_scale=s2.transform(y_train2)\n",
    "#y_train038_scale=s2.transform(y_train1)\n",
    "x_train038_scale=x_train.to_numpy()\n",
    "y_train038_scale=y_train.to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "#y_train_scale=s2.fit_transform(y_train[['DOA']])\n",
    "#y_val_scale = s2.transform(val_ytest[['DOA']])\n",
    "#y_test_scale =s2.transform(y_test[['DOA']])\n",
    "#y_test2_scale=s2.transform(y_test2[['DOA']])\n",
    "\n",
    "#s3=MinMaxScaler(feature_range=(0,1))\n",
    "#y_train_scale = s3.fit_transform(train[['DOA']])\n",
    "#y_train_scale= y_train.to_numpy()\n",
    "\n",
    "#s4=MinMaxScaler(feature_range=(0,1))\n",
    "#y_test_scale = s4.fit_transform(test[['DOA']])\n",
    "#y_test_scale = y_test.to_numpy()\n",
    "#y_test2_scale = y_test2.to_numpy()\n",
    "print(len(x_train_scale))\n",
    "print(len(y_train_scale))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the Features from -1 to 1 so that Training is Easier for the Model ( 038 Train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the Features and Labels from [-1,1]\n",
    "\n",
    "s1=MinMaxScaler(feature_range=(0,1))\n",
    "#s1=MinMaxScaler(feature_range=(0,1))\n",
    "x_train_scale=s1.fit_transform(x_train1)\n",
    "\n",
    "#s2=MinMaxScaler(feature_range=(0,1))\n",
    "#s2=MinMaxScaler(feature_range=(0,1))\n",
    "x_test_scale=s1.transform(x_test)\n",
    "x_test_scale=x_test_scale\n",
    "x_test_scale[:, 21] = -x_test_scale[:, 21]\n",
    "x_test2_scale=s1.transform(x_test2)\n",
    "x_test2_scale[:, 21] = -x_test2_scale[:, 21]\n",
    "\n",
    "# Scale DOA's from (0 to 1)\n",
    "#s3=MinMaxScaler(feature_range=(0,1))\n",
    "#y_train_scale = s3.fit_transform(train[['DOA']])\n",
    "y_train_scale= y_train1.to_numpy()\n",
    "\n",
    "#s4=MinMaxScaler(feature_range=(0,1))\n",
    "#y_test_scale = s4.fit_transform(test[['DOA']])\n",
    "y_test_scale = y_test.to_numpy()\n",
    "y_test2_scale = y_test2.to_numpy()\n",
    "print(len(x_train_scale))\n",
    "print(len(y_train_scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scale[:,21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_scale[:,21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_DOA_df= pd.DataFrame(y_test_scale, columns=['TEST DOAs'])\n",
    "Test_DOA_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_DOA_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.DataFrame(x_train_scale, columns= ['TWTT','I1', 'Q1', 'I2', 'Q2', 'I3', 'Q3', 'I4', 'Q4', 'I5', 'Q5', 'I6', 'Q6', 'I7', 'Q7', 'I8', 'Q8', 'I9', 'Q9', 'I10', 'Q10','Roll', 'Amplitude'])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shift the DOA's to the Left by one so that the Current I and Q data Align with the current DOA while using TimeSeriesGenerator to Window the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3635099\n",
      "3382112\n",
      "[ 0.00000000e+00 -3.05400003e+00 -5.40000005e-02 ...  7.36260006e+01\n",
      "  7.36260006e+01  7.35780006e+01]\n",
      "3635099\n",
      "[ 0.          3.69000003  2.39400002 ... 76.59600067 76.35000066\n",
      " 76.32600066]\n",
      "3382112\n"
     ]
    }
   ],
   "source": [
    "# Shift the DOA to the left by one to use the current DOA label with the current I and Q data.\n",
    "# Normally the TimeseriesGenerator function uses past values to predict the future but we would like current data to help predict the current samples' DOA\n",
    "print(len(y_train_scale))\n",
    "print(len(y_test_scale))\n",
    "y_train_scale=insert(y_train_scale, 0, 0)   # shift combined 002 & 038 port by 1\n",
    "y_train_scale=np.delete(y_train_scale, -1)  #\n",
    "\n",
    "#y_train002_scale=insert(y_train002_scale, 0,0)\n",
    "#y_train002_scale=np.delete(y_train002_scale, -1)\n",
    "y_train038_scale=insert(y_train038_scale, 0,0)\n",
    "y_train038_scale=np.delete(y_train038_scale, -1)\n",
    "\n",
    "\n",
    "\n",
    "y_test_scale=insert(y_test_scale, 0,0)      # shift 038 stbd by 1\n",
    "y_test_scale=np.delete(y_test_scale, -1)    #\n",
    "\n",
    "#y_test2_scale=insert(y_test2_scale, 0,0)    # shift 002 stbd by 1\n",
    "#y_test2_scale=np.delete(y_test2_scale, -1)  #\n",
    "\n",
    "y_val_scale=insert(y_val_scale, 0, 0)       # shift validation set by 1\n",
    "y_val_scale=np.delete(y_val_scale, -1)      #\n",
    "\n",
    "print(y_train_scale)\n",
    "print(len(y_train_scale))\n",
    "print(y_test_scale)\n",
    "print(len(y_test_scale))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Windows Neccesary for the LSTM model using the TimeSeriesGenerator Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3635099"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the windows neccesary for the LSTM model within tensorflow keras\n",
    "# Below are the arguments of the timeseries_dataset_from_array function\n",
    "# The function takes a numpy array and makes a timeseries out of it\n",
    "NumSampsPerPing= 4301-24+1\n",
    "data=x_train_scale # the data to make the windows\n",
    "targets=y_train_scale # time steps in the data (don't need)\n",
    "sequence_length=5 # window length\n",
    "sequence_stride=1# period between successive output sequences\n",
    "sampling_rate=1 # period between successive individual timesteps     within sequences\n",
    "batch_size=8 # number of time series samples in each batch\n",
    "shuffle=False #shuffle the data before making the windows\n",
    "seed=None # is related to shuffle\n",
    "start_index=None # is related to shuffle\n",
    "end_index=None # is related to shuffle\n",
    "n_features=23\n",
    "\n",
    "test_data=x_test_scale\n",
    "test_targets=y_test_scale\n",
    "#test2_data = x_test2_scale\n",
    "#test2_targets = y_test2_scale\n",
    "dataRows = data.shape[0]\n",
    "dataRows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = x_val_scale\n",
    "val_targets = y_val_scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3435099 , 3635099\n"
     ]
    }
   ],
   "source": [
    "#validationStartRow = dataRows - NumSampsPerPing*281\n",
    "validationStartRow = dataRows - 200*1000\n",
    "#validationStartRow = dataRows - 8*1000\n",
    "\n",
    "print(validationStartRow, ',',dataRows)\n",
    "\n",
    "#train_data = data[:validationStartRow-1]\n",
    "train_data = data\n",
    "#   train_data.shape[0]\n",
    "#train_targets = targets[:validationStartRow-1]\n",
    "train_targets = targets\n",
    "#   train_targets.shape[0]\n",
    "#val_data = data[validationStartRow:]\n",
    "#   val_data.shape[0], dataRows-validationStartRow\n",
    "#y_val_scale = y_train_scale[validationStartRow:]\n",
    "\n",
    "#val_targets = targets[validationStartRow:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape , train_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data.shape , val_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#inputs=TimeseriesGenerator(data, targets,sequence_length, batch_size)\n",
    "train_inputs=TimeseriesGenerator(data=train_data,targets=train_targets,length=sequence_length,sampling_rate=sampling_rate,stride=sequence_stride,batch_size=batch_size, shuffle=True)\n",
    "trainentire_inputs = TimeseriesGenerator(data=data,targets=targets,length=sequence_length,sampling_rate=sampling_rate,stride=sequence_stride,batch_size=1024)\n",
    "\n",
    "#train002_inputs=TimeseriesGenerator(data=x_train002_scale,targets=y_train002_scale,length=sequence_length,sampling_rate=sampling_rate,stride=sequence_stride,batch_size=batch_size, shuffle=True)\n",
    "train038_inputs=TimeseriesGenerator(data=x_train038_scale,targets=y_train038_scale,length=sequence_length,sampling_rate=sampling_rate,stride=sequence_stride,batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "val_inputs = TimeseriesGenerator(data=val_data,targets=val_targets,length=sequence_length,sampling_rate=sampling_rate,stride=sequence_stride,batch_size=1024, shuffle=False)\n",
    "\n",
    "#test_inputs=TimeseriesGenerator(test_data[0:40000], -1*test_targets[0:40000],sequence_length, batch_size)\n",
    "test_inputs=TimeseriesGenerator(data=test_data,targets=test_targets,length=sequence_length,sampling_rate=sampling_rate,stride=sequence_stride,batch_size=1024)\n",
    "#test_inputs2=TimeseriesGenerator(data=test2_data,targets=test2_targets,length=sequence_length,sampling_rate=sampling_rate,stride=sequence_stride,batch_size=1024)\n",
    "\n",
    "#inputs=tf.keras.preprocessing.timeseries_dataset_from_array(data, targets, sequence_length, sequence_stride, sampling_rate, batch_size, shuffle)\n",
    "#print(type(inputs))\n",
    "\n",
    "#print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abstraction test imports\n",
    "abstraction_test_port = pd.read_csv('D:\\\\OneDrive\\\\OneDrive - University of Massachusetts Dartmouth\\\\ECE457_Senior_Design_ECE5\\\\CSV_Files\\\\0001_1404.038_port.csv')\n",
    "abstraction_test_stbd = pd.read_csv('D:\\\\OneDrive\\\\OneDrive - University of Massachusetts Dartmouth\\\\ECE457_Senior_Design_ECE5\\\\CSV_Files\\\\0001_1404.038_stbd.csv')\n",
    "# Split up the features and labels from both the training and testing datasets\n",
    "#x_train=train.iloc[:,4:24]\n",
    "\n",
    "Xatest_port=abstraction_test_port.iloc[:,3:24]\n",
    "#x_train['TWTT']=train.iloc[:,28]  I feel as though the TWTT has NO impact on the DOA so we should NOT include it in training\n",
    "Xatest_port['Amplitude']=abstraction_test_port.iloc[:,29]\n",
    "\n",
    "\n",
    "#x_test=test.iloc[:,4:24]\n",
    "Xatest_stbd=abstraction_test_stbd.iloc[:,3:24]\n",
    "#x_test['TWTT']=test.iloc[:,28] I feel as though the TWTT has NO impact on the DOA so we should NOT include it in training\n",
    "Xatest_stbd['Amplitude']=abstraction_test_stbd.iloc[:,29]\n",
    "\n",
    "Yatest_port=abstraction_test_port.iloc[:,26]\n",
    "\n",
    "Yatest_stbd=abstraction_test_stbd.iloc[:,26]\n",
    "\n",
    "s10=MinMaxScaler(feature_range=(0,1))\n",
    "#s1=MinMaxScaler(feature_range=(0,1))\n",
    "Xatest_port_scale=s10.fit_transform(Xatest_port)\n",
    "\n",
    "s20=MinMaxScaler(feature_range=(0,1))\n",
    "#s2=MinMaxScaler(feature_range=(0,1))\n",
    "Xatest_stbd_scale=s20.fit_transform(Xatest_stbd)\n",
    "#x_test_scale=x_test_scale\n",
    "\n",
    "# Scale DOA's from (0 to 1)\n",
    "s30=MinMaxScaler(feature_range=(0,1))\n",
    "#y_train_scale = s3.fit_transform(train[['DOA']])\n",
    "Yatest_port_scale= Yatest_port.to_numpy()\n",
    "\n",
    "s40=MinMaxScaler(feature_range=(0,1))\n",
    "#y_test_scale = s4.fit_transform(test[['DOA']])\n",
    "Yatest_stbd_scale= Yatest_stbd.to_numpy()\n",
    "\n",
    "print(len(Xatest_port_scale))\n",
    "print(len(Xatest_stbd_scale))\n",
    "\n",
    "print(len(Yatest_port_scale))\n",
    "print(len(Yatest_stbd_scale))\n",
    "Yatest_port_scale=insert(Yatest_port_scale, 0, 0)\n",
    "Yatest_port_scale=np.delete(Yatest_port_scale, -1)\n",
    "Yatest_stbd_scale=insert(Yatest_stbd_scale, 0,0)\n",
    "Yatest_stbd_scale=np.delete(Yatest_stbd_scale, -1)\n",
    "print(Yatest_port_scale)\n",
    "print(len(Yatest_port_scale))\n",
    "print(Yatest_stbd_scale)\n",
    "print(len(Yatest_stbd_scale))\n",
    "\n",
    "\n",
    "abstraction_test_port_inputs=TimeseriesGenerator(data=Xatest_port_scale,targets=Yatest_port_scale,length=sequence_length,sampling_rate=sampling_rate,stride=sequence_stride,batch_size=batch_size)\n",
    "abstraction_test_stbd_inputs=TimeseriesGenerator(data=Xatest_stbd_scale,targets=Yatest_stbd_scale,length=sequence_length,sampling_rate=sampling_rate,stride=sequence_stride,batch_size=batch_size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the first couple of samples to see if everything is lining up\n",
    "for i in range(100):\n",
    "\tx, y = train_inputs[i]\n",
    "\tprint('%s => %s' % (x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the first couple of samples to see if everything everything is lining up\n",
    "for i in range(100):\n",
    "\tx, y = test_inputs[i]\n",
    "\tprint('%s => %s' % (x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Model's Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear the model!\n",
    "model = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With all the preproccessing done, it is time to define the model\n",
    "# Define the LSTM Model\n",
    "model= Sequential(name='MLDOASequential')\n",
    "model.add(LSTM(units=192, name='LSTM1', activation='tanh', input_shape=(sequence_length,n_features), return_sequences=True))\n",
    "model.add(LSTM(units=192, name='LSTM2', activation='tanh', input_shape=(sequence_length,n_features), return_sequences=False))\n",
    "#model.add(LSTM(units=44, name='LSTM1', activation='tanh', input_shape=(sequence_length,n_features), return_sequences=False))\n",
    "\n",
    "#model.add(LSTM(units=64, name='LSTM1', activation='tanh', batch_input_shape=(batch_size, sequence_length, n_features),input_shape=(sequence_length,n_features), return_sequences=True, stateful=False, bias_initializer='ones'))\n",
    "#model.add(LSTM(units=64, name='LSTM1', activation='tanh', input_shape=(sequence_length,n_features), return_sequences=True, stateful=False, bias_initializer='Ones'))\n",
    "#model.add(Dense(units=))\n",
    "#model.add(Dense(units=300, name='Dense1', activation = 'relu'))\n",
    "#model.add(Dropout(0.2, name='Dropout1'))\n",
    "\n",
    "#model.add(LSTM(units=416, name='LSTM2', activation='tanh', return_sequences=True, stateful=False, bias_initializer='ones'))\n",
    "#model.add(Dense(units=500, name='Dense2'))\n",
    "#model.add(Dense(units=100, activation='relu'))\n",
    "#model.add(Dropout(0.1, name='Dropout2'))\n",
    "\n",
    "#model.add(LSTM(units=312, name='LSTM3', activation='tanh', return_sequences=False, stateful=False, bias_initializer='Ones'))\n",
    "#model.add(Dense(units=300, name='Dense3', activation='relu'))\n",
    "\n",
    "#model.add(Dropout(0.3, name='Dropout1'))\n",
    "\n",
    "#model.add(Dense(units=10, name='Dense4', activation='relu', input_shape=(sequence_length,n_features)))\n",
    "model.add(Dense(units=192, name='Dense1', activation='relu'))\n",
    "#model.add(Dropout(0.2, name='Dropout2'))\n",
    "model.add(Dense(units=192, name='Dense2', activation='relu'))\n",
    "#model.add(Dropout(0.3, name='Dropout3'))\n",
    "#model.add(Dense(units=96, name='Dense3', activation='relu'))\n",
    "#model.add(Dropout(0.2, name='Dropout3'))\n",
    "#model.add(Dense(units=30, name='Dense4', activation='relu'))\n",
    "#model.add(Dropout(0.2, name='Dropout4'))\n",
    "#model.add(Dense(units=30, name='Dense5', activation='relu'))\n",
    "#model.add(Dropout(0.2, name='Dropout5'))\n",
    "#model.add(Dense(units=10, name='Dense9', activation='relu'))\n",
    "#model.add(Dropout(0.2, name='Dropout6'))\n",
    "#model.add(LSTM(units=84, name='LSTM3', activation='tanh', return_sequences=True))\n",
    "#model.add(Dense(units=100))\n",
    "#model.add(Dense(units=100, activation = 'linear'))\n",
    "#model.add(Dropout(0.2))\n",
    "#model.add(LSTM(units=320, activation='tanh', return_sequences=True))\n",
    "#model.add(Dropout(0.2))\n",
    "#model.add(LSTM(units=168, name='LSTM4', activation='tanh'))\n",
    "#model.add(Dense(units=100))\n",
    "#model.add(Dense(units=100, activation = 'linear'))\n",
    "#model.add(Dropout(0.2))\n",
    "#model.add(LSTM(units=480))\n",
    "#model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model.add(Dense(units=1, name='DenseOutput', activation='linear')) #one output (namely: DOA)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MLDOASequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " LSTM1 (LSTM)                (None, 5, 96)             46080     \n",
      "                                                                 \n",
      " LSTM2 (LSTM)                (None, 96)                74112     \n",
      "                                                                 \n",
      " Dense1 (Dense)              (None, 96)                9312      \n",
      "                                                                 \n",
      " Dense2 (Dense)              (None, 96)                9312      \n",
      "                                                                 \n",
      " Dense3 (Dense)              (None, 96)                9312      \n",
      "                                                                 \n",
      " DenseOutput (Dense)         (None, 1)                 97        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 148,225\n",
      "Trainable params: 148,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# With all the preproccessing done, it is time to define the model\n",
    "# Define the LSTM Model\n",
    "model= Sequential(name='MLDOASequential')\n",
    "# Add the LSTM Layers, (Last one must have return_sequences=False)\n",
    "model.add(LSTM(units=96, name='LSTM1', activation='tanh', input_shape=(sequence_length,n_features), return_sequences=True))\n",
    "model.add(LSTM(units=96, name='LSTM2', activation='tanh', input_shape=(sequence_length,n_features), return_sequences=False))\n",
    "# Add Dense Layers to learn towards DOA output from LSTM outputs\n",
    "model.add(Dense(units=96, name='Dense1', activation='relu'))\n",
    "model.add(Dense(units=96, name='Dense2', activation='relu'))\n",
    "model.add(Dense(units=96, name='Dense3', activation='relu'))\n",
    "# Add output Dense Layer\n",
    "model.add(Dense(units=1, name='DenseOutput', activation='linear'))\n",
    "# print out each layer of the model to validate it \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MLDOASequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " LSTM1 (LSTM)                (None, 36, 192)           165888    \n",
      "                                                                 \n",
      " LSTM2 (LSTM)                (None, 192)               295680    \n",
      "                                                                 \n",
      " Dense1 (Dense)              (None, 192)               37056     \n",
      "                                                                 \n",
      " Dense2 (Dense)              (None, 192)               37056     \n",
      "                                                                 \n",
      " DenseOutput (Dense)         (None, 1)                 193       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 535,873\n",
      "Trainable params: 535,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Model using the Specified Hyperparmeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch learning rate scheduler for 10 epochs.\n",
    "def EpochScheduler10_2(epoch, lr):\n",
    "    if epoch == 0:\n",
    "        return 0.1\n",
    "    if epoch == 1:\n",
    "        return 0.1\n",
    "    elif epoch == 2:\n",
    "        return 0.1\n",
    "    elif epoch == 3:\n",
    "        return 0.05\n",
    "    elif epoch == 4:\n",
    "        return 0.05\n",
    "    elif epoch == 5:\n",
    "        return 0.05\n",
    "    elif epoch == 6:\n",
    "        return 0.025\n",
    "    elif epoch == 7:\n",
    "        return 0.025\n",
    "    elif epoch == 8:\n",
    "        return 0.025\n",
    "    elif epoch == 9:\n",
    "        return 0.01\n",
    "    elif epoch == 10:\n",
    "        return 0.01\n",
    "    elif epoch == 11:\n",
    "        return 0.01\n",
    "    else:\n",
    "        return 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch learning rate scheduler for 10 epochs.\n",
    "def EpochScheduler10(epoch, lr):\n",
    "    if epoch == 0:\n",
    "        return 0.01\n",
    "    if epoch == 1:\n",
    "        return 0.01\n",
    "    elif epoch == 2:\n",
    "        return 0.01\n",
    "    elif epoch == 3:\n",
    "        return 0.005\n",
    "    elif epoch == 4:\n",
    "        return 0.005\n",
    "    elif epoch == 5:\n",
    "        return 0.005\n",
    "    elif epoch == 6:\n",
    "        return 0.0025\n",
    "    elif epoch == 7:\n",
    "        return 0.0025\n",
    "    elif epoch == 8:\n",
    "        return 0.0025\n",
    "    elif epoch == 9:\n",
    "        return 0.001\n",
    "    elif epoch == 10:\n",
    "        return 0.001\n",
    "    elif epoch == 11:\n",
    "        return 0.001\n",
    "    else:\n",
    "        return 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch,lr):\n",
    "    if epoch<=1:\n",
    "        return lr\n",
    "    elif epoch>=2 | epoch<=4:\n",
    "        #return lr/1.65\n",
    "        return lr/1.55\n",
    "    else:\n",
    "        #return lr * tf.math.exp(-0.5)\n",
    "        return lr * tf.math.exp(-0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now it is time to train the model\n",
    "#opt=tf.keras.optimizers.Adam(learning_rate=0.00007)#,decay=1e-5)\n",
    "opt=tf.keras.optimizers.Adam(learning_rate=0.003)#,decay=1e-5)\n",
    "#opt = tf.keras.optimizers.Adam()\n",
    "mMSE = tf.keras.metrics.MeanSquaredError()     # metric for Mean Squared Error\n",
    "mRMSE = tf.keras.metrics.RootMeanSquaredError()\n",
    "huberLoss = tf.keras.losses.Huber(delta=12)\n",
    "#model.compile(loss='mse', optimizer=opt, metrics=[mMSE, mRMSE])\n",
    "#model.compile(loss=huberLoss, optimizer=opt, metrics=[mMSE, mRMSE])\n",
    "model.compile(loss='mae', optimizer=opt, metrics=[mMSE, mRMSE])\n",
    "\n",
    "# Allow for early stopping so that the model does not overfit the training dataset\n",
    "es= EarlyStopping(monitor='val_loss', mode='min',verbose=1,patience=10)\n",
    "#es= EarlyStopping(monitor='loss', mode='min',verbose=1,patience=10)\n",
    "# change learning rates per epoch\n",
    "lrCallback = tf.keras.callbacks.LearningRateScheduler(EpochScheduler10_2)\n",
    "sc = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "# Model Checkpoint to save good runs\n",
    "cp = ModelCheckpoint('model/', save_best_only=True)\n",
    "#cp = ModelCheckpoint('model/', monitor='loss',save_best_only=True)\n",
    "\n",
    "t0=time.time()\n",
    "#history= model.fit(inputs,steps_per_epoch=4000,epochs=200,verbose=1, callbacks=[es])\n",
    "#history= model.fit(train_inputs, steps_per_epoch=4000, validation_data=val_inputs, epochs=100, callbacks=[lrCallback, cp])\n",
    "#history= model.fit(train_inputs, epochs=1, batch_size=None,callbacks=[cp, es])\n",
    "#history= model.fit(train_inputs, epochs=75, steps_per_epoch=1782, validation_steps=10720,validation_data=val_inputs, batch_size=None,callbacks=[cp])\n",
    "#history= model.fit(train_inputs, epochs=15,validation_data=val_inputs, batch_size=None,callbacks=[cp, sc])\n",
    "\n",
    "#history = model.fit(train_inputs, epochs = 60, steps_per_epoch = 1500, validation_data=val_inputs, batch_size=None,callbacks=[cp, es])\n",
    "#history = model.fit(train_inputs, epochs = 15, steps_per_epoch = 5000, batch_size=None,callbacks=[cp, es, sc])\n",
    "history = model.fit(train_inputs, epochs = 150, steps_per_epoch = 10000, batch_size=None, validation_data=val_inputs,callbacks=[cp, es, sc])\n",
    "\n",
    "t1=time.time()\n",
    "print(\"The total run time to train was %.2f seconds\"%(t1-t0))\n",
    "\n",
    "# plot the loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "4996/5000 [============================>.] - ETA: 0s - loss: 31.0220 - mean_squared_error: 100.9711 - root_mean_squared_error: 10.0484"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) LSTM1_input with unsupported characters which will be renamed to lstm1_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000015DA08B0820> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000015DA0BBA040> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 189s 37ms/step - loss: 30.9983 - mean_squared_error: 100.8926 - root_mean_squared_error: 10.0445 - val_loss: 2.6504 - val_mean_squared_error: 8.1557 - val_root_mean_squared_error: 2.8558 - lr: 0.0100\n",
      "Epoch 2/15\n",
      "4998/5000 [============================>.] - ETA: 0s - loss: 2.6184 - mean_squared_error: 6.7638 - root_mean_squared_error: 2.6007"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) LSTM1_input with unsupported characters which will be renamed to lstm1_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000015DA08B0820> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000015DA0BBA040> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 178s 36ms/step - loss: 2.6196 - mean_squared_error: 6.7656 - root_mean_squared_error: 2.6011 - val_loss: 2.0727 - val_mean_squared_error: 4.5864 - val_root_mean_squared_error: 2.1416 - lr: 0.0100\n",
      "Epoch 3/15\n",
      "4999/5000 [============================>.] - ETA: 0s - loss: 1.5521 - mean_squared_error: 3.4583 - root_mean_squared_error: 1.8596"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) LSTM1_input with unsupported characters which will be renamed to lstm1_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000015DA08B0820> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000015DA0BBA040> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 180s 36ms/step - loss: 1.5519 - mean_squared_error: 3.4578 - root_mean_squared_error: 1.8595 - val_loss: 0.9637 - val_mean_squared_error: 2.0028 - val_root_mean_squared_error: 1.4152 - lr: 0.0065\n",
      "Epoch 4/15\n",
      "1285/5000 [======>.......................] - ETA: 1:43 - loss: 1.0240 - mean_squared_error: 2.1427 - root_mean_squared_error: 1.4638"
     ]
    }
   ],
   "source": [
    "#Now it is time to train the model\n",
    "opt=tf.keras.optimizers.Adam(learning_rate=0.01)#,decay=1e-5)\n",
    "mMSE = tf.keras.metrics.MeanSquaredError()\n",
    "mRMSE = tf.keras.metrics.RootMeanSquaredError()\n",
    "huberLoss = tf.keras.losses.Huber(delta=10)\n",
    "# Compile Model with specified settings\n",
    "model.compile(loss=huberLoss, optimizer=opt, metrics=[mMSE, mRMSE])\n",
    "# Allow for early stopping so that the model does not overfit the training dataset\n",
    "es= EarlyStopping(monitor='val_loss', mode='min',verbose=1,patience=10)\n",
    "# change learning rates per epoch\n",
    "sc = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "# Model Checkpoint to save good runs\n",
    "cp = ModelCheckpoint('model/', save_best_only=True)\n",
    "t0=time.time()\n",
    "# Start Training\n",
    "history = model.fit(train_inputs, epochs = 15, steps_per_epoch = 5000, batch_size=None, \\\n",
    "    validation_data=val_inputs,callbacks=[cp, es, sc])\n",
    "t1=time.time()\n",
    "print(\"The total run time to train was %.2f seconds\"%(t1-t0))\n",
    "# plot the loss function\n",
    "plt.figure()\n",
    "plt.semilogy(history.history['loss'])\n",
    "plt.semilogy(history.history['val_loss'])\n",
    "#plt.semilogy(history.history['lr'])\n",
    "plt.xlabel('epoch'); plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.semilogy(history.history['loss'])\n",
    "plt.semilogy(history.history['val_loss'])\n",
    "#plt.semilogy(history.history['lr'])\n",
    "plt.xlabel('epoch'); plt.ylabel('loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt=tf.keras.optimizers.Adam(learning_rate=0.003)#,decay=1e-5)\n",
    "#opt = tf.keras.optimizers.Adam()\n",
    "mMSE = tf.keras.metrics.MeanSquaredError()     # metric for Mean Squared Error\n",
    "mRMSE = tf.keras.metrics.RootMeanSquaredError()\n",
    "huberLoss = tf.keras.losses.Huber(delta=12)\n",
    "#model.compile(loss='mse', optimizer=opt, metrics=[mMSE, mRMSE])\n",
    "#model.compile(loss=huberLoss, optimizer=opt, metrics=[mMSE, mRMSE])\n",
    "model.compile(loss='mae', optimizer=opt, metrics=[mMSE, mRMSE])\n",
    "history = model.fit(train038_inputs, epochs = 15, steps_per_epoch = 20000, batch_size=None, validation_data=val_inputs,callbacks=[cp, es, sc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(model, filepath=\"D:\\\\OneDrive\\\\OneDrive - University of Massachusetts Dartmouth\\\\ECE457_Senior_Design_ECE5\\\\SavedModels\\\\MB\\\\Mar10_2022\\\\model_row43.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('model/')\n",
    "#model = keras.models.load_model('model_3_13_22_epoch4/model/')\n",
    "#model = keras.models.load_model(filepath=\"D:\\\\OneDrive\\\\OneDrive - University of Massachusetts Dartmouth\\\\ECE457_Senior_Design_ECE5\\\\SavedModels\\\\MB\\\\Mar10_2022\\\\model_row12.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainpredicted=model.predict(train_inputs, verbose=1)\n",
    "#valpredicted=model.predict(val_inputs, verbose=1)\n",
    "#trainentirepredicted=model.predict(trainentire_inputs, verbose=1)\n",
    "predicted038=model.predict(test_inputs, verbose=1)\n",
    "predicted002=model.predict(test_inputs2, verbose=1)\n",
    "#trainpredicted.shape, valpredicted.shape, predicted.shape, trainentirepredicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainentirepredicted=model.predict(trainentire_inputs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted.shape, trainentirepredicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "port_abstraction_test_predicted=model.predict(abstraction_test_port_inputs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yatest_port_scale\n",
    "#val_targets\n",
    "plt.figure(facecolor='white')\n",
    "plt.plot(Yatest_port_scale[0:4278*3])\n",
    "plt.plot(port_abstraction_test_predicted[0:4278*3])\n",
    "plt.title(\"Port Abstraction Test (Actual vs. Predicted)\")\n",
    "plt.xlabel('Samples')\n",
    "plt.ylabel('DOA in degrees')\n",
    "plt.legend(['Actual','Predicted'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainpredicted.shape, valpredicted.shape,trainpredicted.shape[0]+valpredicted.shape[0], predicted.shape, trainentirepredicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted=model.predict(test_inputs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_targets\n",
    "plt.figure(facecolor='white')\n",
    "plt.plot(val_targets[0:2278*3])\n",
    "plt.plot(valpredicted[0:2278*3])\n",
    "plt.title(\"Validation (Actual vs. Predicted)\")\n",
    "plt.xlabel('Samples')\n",
    "plt.ylabel('DOA in degrees')\n",
    "plt.legend(['Actual','Predicted'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(facecolor='white')\n",
    "#plt.plot(y_train[0:2278*3])\n",
    "plt.plot(y_train[0:80000])\n",
    "#plt.plot(trainentirepredicted[0:2278*3])\n",
    "plt.plot(trainentirepredicted[0:80000])\n",
    "plt.title(\"Training (Actual vs. Predicted)\")\n",
    "plt.xlabel('Samples')\n",
    "plt.ylabel('DOA in degrees')\n",
    "plt.legend(['Actual','Predicted'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot STBD Predicted for 002\n",
    "zerosArray= np.arange(sequence_length)*0\n",
    "predictedShifted002=np.append(zerosArray, predicted002)\n",
    "plt.figure(facecolor='white')\n",
    "plt.plot(y_test2_scale[0:4278*4])\n",
    "#plt.plot(y_test2_scale[0:80000])\n",
    "plt.plot(predictedShifted002[0:4278*4])\n",
    "#plt.plot(predictedShifted002[0:80000])\n",
    "plt.title(\"Testing 002(Actual vs. Predicted)\")\n",
    "plt.xlabel('Samples')\n",
    "plt.ylabel('DOA in degrees')\n",
    "plt.legend(['Actual','Predicted'])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot STBD Predicted for 038\n",
    "zerosArray= np.arange(sequence_length)*0\n",
    "predictedShifted038=np.append(zerosArray, predicted038)\n",
    "plt.figure(facecolor='white')\n",
    "plt.plot(y_test_scale[0:4278*4])\n",
    "#plt.plot(y_test[0:80000])\n",
    "plt.plot(predictedShifted038[0:4278*4])\n",
    "#plt.plot(predictedShifted038[0:80000])\n",
    "plt.title(\"Testing 038(Actual vs. Predicted)\")\n",
    "plt.xlabel('Samples')\n",
    "plt.ylabel('DOA in degrees')\n",
    "plt.legend(['Actual','Predicted'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Model, Predict the DOA's on the Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the model to predict on the testing dataset\n",
    "#for right now test_inputs has only the 40,001 samples\n",
    "predicted=model.predict(test_inputs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put the predicted 038 DOA's back into a csv file format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ping |  Num Samp Num | PORT or STBD (0 or 1) |  TWTT |  Predicted DOA   <=======Output columns.\n",
    "OutputCSVdf=test.iloc[:,[0,1,2,3]]\n",
    "#OutputCSVdf= pd.DataFrame(test.iloc[:,[0,1,2,3]], columns=['PingNumber','SampNumber','PortStbd', 'SampleTime'])\n",
    "zerosArray= np.arange(sequence_length)*0\n",
    "predictedShifted038=np.append(zerosArray, predicted038)\n",
    "Predicteddf= pd.DataFrame(predictedShifted038,columns=['PredictedDOA'])\n",
    "OutputCSVdf=OutputCSVdf.join(Predicteddf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OutputCSVdf.to_csv(path_or_buf=\"D:\\\\OneDrive\\\\OneDrive - University of Massachusetts Dartmouth\\\\ECE457_Senior_Design_ECE5\\\\AIOutput_CSV_Files\\\\mb_predictions\\\\PredictedOutputTestMB43.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PortOutputCSVdf=train.iloc[:,[0,1,2,3]]\n",
    "#OutputCSVdf= pd.DataFrame(test.iloc[:,[0,1,2,3]], columns=['PingNumber','SampNumber','PortStbd', 'SampleTime'])\n",
    "zerosArray= np.arange(sequence_length)*0\n",
    "portPredictedShifted=np.append(zerosArray, trainentirepredicted)\n",
    "portPredicteddf= pd.DataFrame(portPredictedShifted,columns=['PredictedDOA'])\n",
    "PortOutputCSVdf=PortOutputCSVdf.join(portPredicteddf)\n",
    "PortOutputCSVdf.to_csv(path_or_buf=\"D:\\\\OneDrive\\\\OneDrive - University of Massachusetts Dartmouth\\\\ECE457_Senior_Design_ECE5\\\\AIOutput_CSV_Files\\\\mb_predictions\\\\PredictedOutputTrainMB43.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StbdOriginalOutputCSVdf = test.iloc[:,[0,1,2,3,26]]\n",
    "StbdOriginalOutputCSVdf.to_csv(path_or_buf=\"D:\\\\OneDrive\\\\OneDrive - University of Massachusetts Dartmouth\\\\ECE457_Senior_Design_ECE5\\\\AIOutput_CSV_Files\\\\mb_predictions\\\\Stbd_038_forEric.csv\")\n",
    "PortOriginalOutputCSVdf = train.iloc[:,[0,1,2,3,26]]\n",
    "PortOriginalOutputCSVdf.to_csv(path_or_buf=\"D:\\\\OneDrive\\\\OneDrive - University of Massachusetts Dartmouth\\\\ECE457_Senior_Design_ECE5\\\\AIOutput_CSV_Files\\\\mb_predictions\\\\Port_038_forEric.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.iloc[:,[0,1,2,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zerosArray= np.arange(sequence_length)*0\n",
    "zerosArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedShifted=np.append(zerosArray, predicted)\n",
    "predictedShifted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OutputCSVdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predicted[0:21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test[10:21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(predicted)\n",
    "predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_reshape= predicted.reshape(len(predicted),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(facecolor='white')\n",
    "plt.plot(predicted[0:40000], 'orange')\n",
    "plt.title(\"Actual\")\n",
    "plt.xlabel('Samples')\n",
    "plt.ylabel('DOA in degrees')\n",
    "plt.legend(['Predicted'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the Actual Testing DOA's to the Predicted DOA's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "\n",
    "\n",
    "plt.figure(facecolor='white')\n",
    "plt.plot(y_test[0:10], '.')\n",
    "plt.plot(predicted[0:10], '.')\n",
    "plt.title(\"Actual\")\n",
    "plt.legend(['Actual','Predicted'])\n",
    "plt.xlabel('Samples')\n",
    "plt.ylabel('DOA in degrees')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(facecolor='white')\n",
    "plt.plot(y_test[0:40000])\n",
    "plt.plot(predicted_reshape[0:40000])\n",
    "plt.title(\"Actual\")\n",
    "plt.xlabel('Samples')\n",
    "plt.ylabel('DOA in degrees')\n",
    "plt.legend(['Actual','Predicted'])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(facecolor='white')\n",
    "plt.plot(y_test[0:40000])\n",
    "plt.title(\"Actual\")\n",
    "plt.xlabel('Samples')\n",
    "plt.ylabel('DOA in degrees')\n",
    "plt.legend(['Actual'])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(facecolor='white')\n",
    "plt.plot(predicted_reshape[0:40000], 'orange')\n",
    "plt.title(\"Actual\")\n",
    "plt.xlabel('Samples')\n",
    "plt.ylabel('DOA in degrees')\n",
    "plt.legend(['Predicted'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test[0:50000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2= pd.DataFrame(predicted, columns= ['DOA'])\n",
    "df2"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "674a9451ed4de84c8c52b62b7b95bc1f8984ddc9599597b49394de9958455427"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 ('keras_tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
